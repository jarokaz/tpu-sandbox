{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ],
   "outputs": [],
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TPU node sandbox\n",
    "\n"
   ],
   "metadata": {
    "id": "MfBg1C5NB3X0"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Setup"
   ],
   "metadata": {
    "id": "ek5Hop74NVKm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from cloud_tpu_client import Client\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import gin\n",
    "\n",
    "from official.common import distribute_utils\n",
    "# pylint: disable=unused-import\n",
    "from official.common import registry_imports\n",
    "# pylint: enable=unused-import\n",
    "from official.common import flags as tfm_flags\n",
    "from official.core import task_factory\n",
    "from official.core import train_lib\n",
    "from official.core import train_utils\n",
    "from official.modeling import performance\n",
    "from official.nlp import continuous_finetune_lib\n",
    "from official.core import config_definitions\n",
    "from official.core import exp_factory\n",
    "from official.modeling import hyperparams"
   ],
   "outputs": [],
   "metadata": {
    "id": "Cw0WRaChRxTL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configure GCP settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "TPU_NODE_NAME = 'jk-tpu-node'\n",
    "ZONE = 'us-central1-a'\n",
    "GCS_BUCKET = 'gs://jk-tpu-staging'\n",
    "\n",
    "c = Client(tpu=TPU_NODE_NAME, zone=ZONE)\n",
    "\n",
    "print(c.accelerator_type())\n",
    "print(c.name())\n",
    "print(c.state())\n",
    "print(c.runtime_version())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "v3-8\n",
      "jk-tpu-node\n",
      "READY\n",
      "2.5.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "c.configure_tpu_version(tf.__version__, restart_type='ifNeeded')\n",
    "c.wait_for_healthy()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:root:TPU \"jk-tpu-node\" is healthy.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: The TPU initialization code has to be at the beginning of your program."
   ],
   "metadata": {
    "id": "dCqWMqvtwOLs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_NODE_NAME)\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-11 18:57:09.250576: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.122.28.50:8470}\n",
      "2021-09-11 18:57:09.250641: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:33496}\n",
      "2021-09-11 18:57:09.255275: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.122.28.50:8470}\n",
      "2021-09-11 18:57:09.255350: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:33496}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:TPU system jk-tpu-node has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:TPU system jk-tpu-node has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: jk-tpu-node\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: jk-tpu-node\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
     ]
    }
   ],
   "metadata": {
    "id": "dKPqF8d1wJCV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "DATASET_LOCATION = \"gs://cloud-samples-data/vertex-ai/community-content/datasets/MNLI\"\n",
    "TRAIN_FILE = f\"{DATASET_LOCATION}/mnli_train.tf_record\"\n",
    "EVAL_FILE = f\"{DATASET_LOCATION}/mnli_valid.tf_record\"\n",
    "METADATA_FILE = f\"{DATASET_LOCATION}/metadata.json\"\n",
    "\n",
    "CONFIG_FILE = 'glue_mnli_matched.yaml'\n",
    "EXPERIMENT = 'bert/sentence_prediction'\n",
    "HUB_MODULE_URL = 'gs://tfhub-modules/tensorflow/bert_en_cased_L-24_H-1024_A-16/4/uncompressed'\n",
    "INIT_CHECKPOINT = 'gs://jk-tpu-staging/uncased_L-12-H-768_A-12'\n",
    "LOGGING_DIR = f'{GCS_BUCKET}/job'\n",
    "MODEL_DIR = f'{GCS_BUCKET}/model'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "%%writefile {CONFIG_FILE}\n",
    "\n",
    "task:\n",
    "  hub_module_url: ''\n",
    "  model:\n",
    "    num_classes: 3\n",
    "  init_checkpoint: ''\n",
    "  metric_type: 'accuracy'\n",
    "  train_data:\n",
    "    drop_remainder: true\n",
    "    global_batch_size: 32\n",
    "    input_path: ''\n",
    "    is_training: true\n",
    "    seq_length: 128\n",
    "    label_type: 'int'\n",
    "  validation_data:\n",
    "    drop_remainder: false\n",
    "    global_batch_size: 32\n",
    "    input_path: ''\n",
    "    is_training: false\n",
    "    seq_length: 128\n",
    "    label_type: 'int'\n",
    "trainer:\n",
    "  checkpoint_interval: 3000\n",
    "  optimizer_config:\n",
    "    learning_rate:\n",
    "      polynomial:\n",
    "        # 100% of train_steps.\n",
    "        decay_steps: 36813\n",
    "        end_learning_rate: 0.0\n",
    "        initial_learning_rate: 3.0e-05\n",
    "        power: 1.0\n",
    "      type: polynomial\n",
    "    optimizer:\n",
    "      type: adamw\n",
    "    warmup:\n",
    "      polynomial:\n",
    "        power: 1\n",
    "        # ~10% of train_steps.\n",
    "        warmup_steps: 3681\n",
    "      type: polynomial\n",
    "  steps_per_loop: 1000\n",
    "  summary_interval: 1000\n",
    "  # Training data size 392,702 examples, 3 epochs.\n",
    "  train_steps: 36813\n",
    "  validation_interval: 6135\n",
    "  # Eval data size = 9815 examples.\n",
    "  validation_steps: 307\n",
    "  best_checkpoint_export_subdir: 'best_ckpt'\n",
    "  best_checkpoint_eval_metric: 'cls_accuracy'\n",
    "  best_checkpoint_metric_comp: 'higher'\n",
    "runtime:\n",
    "  distribution_strategy: 'multi_worker_mirrored'\n",
    "  all_reduce_alg: 'nccl'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Overwriting glue_mnli_matched.yaml\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "\n",
    "params = hyperparams.override_params_dict(params, CONFIG_FILE, is_strict=True)\n",
    "params.override({\n",
    "    'trainer': {\n",
    "        'train_steps': 2000,\n",
    "        'steps_per_loop': 100,\n",
    "        'summary_interval': 100,\n",
    "        'validation_interval': 2000,\n",
    "        'checkpoint_interval': 2000,  \n",
    "    },\n",
    "\n",
    "    'task': {\n",
    "        'init_checkpoint': INIT_CHECKPOINT,\n",
    "        'train_data': {\n",
    "            'global_batch_size': 128, \n",
    "            'input_path': TRAIN_FILE, \n",
    "        },\n",
    "    \n",
    "        'validation_data': {\n",
    "            'global_batch_size': 128, \n",
    "            'input_path': EVAL_FILE,\n",
    "        },\n",
    "\n",
    "\n",
    "    },\n",
    "\n",
    "    'runtime': {\n",
    "        'tpu': TPU_NODE_NAME,\n",
    "        'distribution_strategy': 'tpu'\n",
    "    }\n",
    "\n",
    "})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "params.task.model.encoder.bert"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BertEncoderConfig(vocab_size=30522, hidden_size=1024, num_layers=12, num_attention_heads=16, hidden_activation='gelu', intermediate_size=4096, dropout_rate=0.1, attention_dropout_rate=0.1, max_position_embeddings=512, type_vocab_size=2, initializer_range=0.02, embedding_size=None, output_range=None, return_all_encoder_outputs=False)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "distribution_strategy = distribute_utils.get_distribution_strategy(\n",
    "        distribution_strategy=params.runtime.distribution_strategy,\n",
    "        tpu_address=params.runtime.tpu,\n",
    "        **params.runtime.model_parallelism())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-11 19:18:41.451121: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.122.28.50:8470}\n",
      "2021-09-11 19:18:41.451221: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:33496}\n",
      "2021-09-11 19:18:41.457570: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.122.28.50:8470}\n",
      "2021-09-11 19:18:41.457624: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:33496}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:TPU system jk-tpu-node has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:TPU system jk-tpu-node has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: jk-tpu-node\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: jk-tpu-node\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "with distribution_strategy.scope():\n",
    "      task = task_factory.get_task(params.task, logging_dir=LOGGING_DIR)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train',\n",
    "        params=params,\n",
    "        model_dir=MODEL_DIR)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "2021-09-11 19:18:56.152462: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 6362, Output num: 291\n",
      "Additional GRPC error information from remote target /job:worker/replica:0/task:0:\n",
      ":{\"created\":\"@1631387936.152299498\",\"description\":\"Error received from peer ipv4:10.122.28.50:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 6362, Output num: 291\",\"grpc_status\":3}\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "restoring or initializing model...\n",
      "initialized model.\n",
      "train | step:      0 | training until step 2000...\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tpu.ipynb",
   "toc_visible": true
  },
  "environment": {
   "name": "common-cpu.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m75"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}