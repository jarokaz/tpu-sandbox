{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "# TPU node sandbox\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ek5Hop74NVKm"
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Cw0WRaChRxTL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "from cloud_tpu_client import Client\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "import gin\n",
    "\n",
    "from official.common import distribute_utils\n",
    "# pylint: disable=unused-import\n",
    "from official.common import registry_imports\n",
    "# pylint: enable=unused-import\n",
    "from official.common import flags as tfm_flags\n",
    "from official.core import task_factory\n",
    "from official.core import train_lib\n",
    "from official.core import train_utils\n",
    "from official.modeling import performance\n",
    "from official.nlp import continuous_finetune_lib\n",
    "from official.core import config_definitions\n",
    "from official.core import exp_factory\n",
    "from official.modeling import hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure GCP settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v3-8\n",
      "jk-tpu-node\n",
      "READY\n",
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "TPU_NODE_NAME = 'jk-tpu-node'\n",
    "ZONE = 'us-central1-a'\n",
    "GCS_BUCKET = 'gs://jk-tpu-staging'\n",
    "\n",
    "c = Client(tpu=TPU_NODE_NAME, zone=ZONE)\n",
    "\n",
    "print(c.accelerator_type())\n",
    "print(c.name())\n",
    "print(c.state())\n",
    "print(c.runtime_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:TPU \"jk-tpu-node\" is healthy.\n"
     ]
    }
   ],
   "source": [
    "c.configure_tpu_version(tf.__version__, restart_type='ifNeeded')\n",
    "c.wait_for_healthy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCqWMqvtwOLs"
   },
   "source": [
    "Note: The TPU initialization code has to be at the beginning of your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dKPqF8d1wJCV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 20:05:17.051805: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-09-13 20:05:17.051894: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-09-13 20:05:17.051916: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jk-tpu-node-1): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: jk-tpu-node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 20:05:17.223667: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-09-13 20:05:17.238361: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.122.28.50:8470}\n",
      "2021-09-13 20:05:17.238415: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34994}\n",
      "2021-09-13 20:05:17.255943: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.122.28.50:8470}\n",
      "2021-09-13 20:05:17.255998: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34994}\n",
      "2021-09-13 20:05:17.256597: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:34994\n",
      "INFO:tensorflow:Initializing the TPU system: jk-tpu-node\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n"
     ]
    }
   ],
   "source": [
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_NODE_NAME)\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOCATION = \"gs://cloud-samples-data/vertex-ai/community-content/datasets/MNLI\"\n",
    "TRAIN_FILE = f\"{DATASET_LOCATION}/mnli_train.tf_record\"\n",
    "EVAL_FILE = f\"{DATASET_LOCATION}/mnli_valid.tf_record\"\n",
    "METADATA_FILE = f\"{DATASET_LOCATION}/metadata.json\"\n",
    "\n",
    "CONFIG_FILE = 'glue_mnli_matched.yaml'\n",
    "EXPERIMENT = 'bert/sentence_prediction'\n",
    "HUB_MODULE_URL = 'gs://tfhub-modules/tensorflow/bert_en_cased_L-24_H-1024_A-16/4/uncompressed'\n",
    "\n",
    "INIT_CHECKPOINT = 'gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12'\n",
    "LOGGING_DIR = f'{GCS_BUCKET}/job'\n",
    "MODEL_DIR = f'{GCS_BUCKET}/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting glue_mnli_matched.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {CONFIG_FILE}\n",
    "\n",
    "task:\n",
    "  hub_module_url: ''\n",
    "  model:\n",
    "    num_classes: 3\n",
    "  init_checkpoint: ''\n",
    "  metric_type: 'accuracy'\n",
    "  train_data:\n",
    "    drop_remainder: true\n",
    "    global_batch_size: 32\n",
    "    input_path: ''\n",
    "    is_training: true\n",
    "    seq_length: 128\n",
    "    label_type: 'int'\n",
    "  validation_data:\n",
    "    drop_remainder: false\n",
    "    global_batch_size: 32\n",
    "    input_path: ''\n",
    "    is_training: false\n",
    "    seq_length: 128\n",
    "    label_type: 'int'\n",
    "trainer:\n",
    "  checkpoint_interval: 3000\n",
    "  optimizer_config:\n",
    "    learning_rate:\n",
    "      polynomial:\n",
    "        # 100% of train_steps.\n",
    "        decay_steps: 36813\n",
    "        end_learning_rate: 0.0\n",
    "        initial_learning_rate: 3.0e-05\n",
    "        power: 1.0\n",
    "      type: polynomial\n",
    "    optimizer:\n",
    "      type: adamw\n",
    "    warmup:\n",
    "      polynomial:\n",
    "        power: 1\n",
    "        # ~10% of train_steps.\n",
    "        warmup_steps: 3681\n",
    "      type: polynomial\n",
    "  steps_per_loop: 1000\n",
    "  summary_interval: 1000\n",
    "  # Training data size 392,702 examples, 3 epochs.\n",
    "  train_steps: 36813\n",
    "  validation_interval: 6135\n",
    "  # Eval data size = 9815 examples.\n",
    "  validation_steps: 307\n",
    "  best_checkpoint_export_subdir: 'best_ckpt'\n",
    "  best_checkpoint_eval_metric: 'cls_accuracy'\n",
    "  best_checkpoint_metric_comp: 'higher'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = exp_factory.get_exp_config(EXPERIMENT)\n",
    "params = hyperparams.override_params_dict(params, CONFIG_FILE, is_strict=True)\n",
    "params.override({\n",
    "    'trainer': {\n",
    "        'train_steps': 2000,\n",
    "        'steps_per_loop': 100,\n",
    "        'summary_interval': 100,\n",
    "        'validation_interval': 2000,\n",
    "        'checkpoint_interval': 2000,  \n",
    "    },\n",
    "\n",
    "    'task': {\n",
    "        'init_checkpoint': INIT_CHECKPOINT,\n",
    "        'train_data': {\n",
    "            'global_batch_size': 256, \n",
    "            'input_path': TRAIN_FILE, \n",
    "        },\n",
    "    \n",
    "        'validation_data': {\n",
    "            'global_batch_size': 256, \n",
    "            'input_path': EVAL_FILE,\n",
    "        },\n",
    "\n",
    "\n",
    "    },\n",
    "\n",
    "    'runtime': {\n",
    "        'tpu': TPU_NODE_NAME,\n",
    "        'distribution_strategy': 'tpu'\n",
    "    }\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertEncoderConfig(vocab_size=30522, hidden_size=768, num_layers=12, num_attention_heads=12, hidden_activation='gelu', intermediate_size=3072, dropout_rate=0.1, attention_dropout_rate=0.1, max_position_embeddings=512, type_vocab_size=2, initializer_range=0.02, embedding_size=None, output_range=None, return_all_encoder_outputs=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.task.model.encoder.bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system jk-tpu-node has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 20:05:40.975600: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.122.28.50:8470}\n",
      "2021-09-13 20:05:40.975736: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34994}\n",
      "2021-09-13 20:05:40.979695: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.122.28.50:8470}\n",
      "2021-09-13 20:05:40.979744: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:34994}\n",
      "WARNING:tensorflow:TPU system jk-tpu-node has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: jk-tpu-node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: jk-tpu-node\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "distribution_strategy = distribute_utils.get_distribution_strategy(\n",
    "        distribution_strategy=params.runtime.distribution_strategy,\n",
    "        tpu_address=params.runtime.tpu,\n",
    "        **params.runtime.model_parallelism())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentencePredictionConfig(init_checkpoint='gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12', model=ModelConfig(num_classes=3, use_encoder_pooler=False, encoder=EncoderConfig(type='bert', albert=AlbertEncoderConfig(vocab_size=30000, embedding_width=128, hidden_size=768, num_layers=12, num_attention_heads=12, hidden_activation='gelu', intermediate_size=3072, dropout_rate=0.0, attention_dropout_rate=0.0, max_position_embeddings=512, type_vocab_size=2, initializer_range=0.02), bert=BertEncoderConfig(vocab_size=30522, hidden_size=768, num_layers=12, num_attention_heads=12, hidden_activation='gelu', intermediate_size=3072, dropout_rate=0.1, attention_dropout_rate=0.1, max_position_embeddings=512, type_vocab_size=2, initializer_range=0.02, embedding_size=None, output_range=None, return_all_encoder_outputs=False), bigbird=BigBirdEncoderConfig(vocab_size=50358, hidden_size=768, num_layers=12, num_attention_heads=12, hidden_activation='gelu', intermediate_size=3072, dropout_rate=0.1, attention_dropout_rate=0.1, max_position_embeddings=4096, num_rand_blocks=3, block_size=64, type_vocab_size=16, initializer_range=0.02, embedding_width=None), mobilebert=MobileBertEncoderConfig(word_vocab_size=30522, word_embed_size=128, type_vocab_size=2, max_sequence_length=512, num_blocks=24, hidden_size=512, num_attention_heads=4, intermediate_size=4096, hidden_activation='gelu', hidden_dropout_prob=0.1, attention_probs_dropout_prob=0.1, intra_bottleneck_size=1024, initializer_range=0.02, use_bottleneck_attention=False, key_query_shared_bottleneck=False, num_feedforward_networks=1, normalization_type='layer_norm', classifier_activation=True, input_mask_dtype='int32'), xlnet=XLNetEncoderConfig(vocab_size=32000, num_layers=24, hidden_size=1024, num_attention_heads=16, head_size=64, inner_size=4096, inner_activation='gelu', dropout_rate=0.1, attention_dropout_rate=0.1, attention_type='bi', bi_data=False, tie_attention_biases=False, memory_length=0, same_length=False, clamp_length=-1, reuse_length=0, use_cls_mask=False, embedding_width=1024, initializer_range=0.02, two_stream=False))), train_data=SentencePredictionDataConfig(input_path='gs://cloud-samples-data/vertex-ai/community-content/datasets/MNLI/mnli_train.tf_record', tfds_name='', tfds_split='', global_batch_size=256, is_training=True, drop_remainder=True, shuffle_buffer_size=100, cache=False, cycle_length=None, block_length=1, deterministic=None, sharding=True, enable_tf_data_service=False, tf_data_service_address=None, tf_data_service_job_name=None, tfds_data_dir='', tfds_as_supervised=False, tfds_skip_decoding_feature='', seed=None, seq_length=128, label_type='int', include_example_id=False), validation_data=SentencePredictionDataConfig(input_path='gs://cloud-samples-data/vertex-ai/community-content/datasets/MNLI/mnli_valid.tf_record', tfds_name='', tfds_split='', global_batch_size=256, is_training=False, drop_remainder=False, shuffle_buffer_size=100, cache=False, cycle_length=None, block_length=1, deterministic=None, sharding=True, enable_tf_data_service=False, tf_data_service_address=None, tf_data_service_job_name=None, tfds_data_dir='', tfds_as_supervised=False, tfds_skip_decoding_feature='', seed=None, seq_length=128, label_type='int', include_example_id=False), init_cls_pooler=False, hub_module_url='', metric_type='accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with distribution_strategy.scope():\n",
    "      task = task_factory.get_task(params.task, logging_dir=LOGGING_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restoring or initializing model...\n",
      "ERROR:tensorflow:Couldn't match files for checkpoint /usr/local/google/home/jacobdevlin/expts/bert_model_releases/uncased_L-12_H-768_A-12/bert_model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Couldn't match files for checkpoint /usr/local/google/home/jacobdevlin/expts/bert_model_releases/uncased_L-12_H-768_A-12/bert_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized model.\n",
      "train | step:      0 | training until step 2000...\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['pooler_transform/kernel:0', 'pooler_transform/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train | step:    100 | steps/sec:    1.6 | output: \n",
      "    {'cls_accuracy': 0.3380078,\n",
      "     'learning_rate': 7.3350293e-07,\n",
      "     'training_loss': 1.1024282}\n",
      "saved checkpoint to gs://jk-tpu-staging/model/ckpt-100.\n",
      "train | step:    200 | steps/sec:    4.3 | output: \n",
      "    {'cls_accuracy': 0.34816405,\n",
      "     'learning_rate': 1.4670059e-06,\n",
      "     'training_loss': 1.0992756}\n",
      "train | step:    300 | steps/sec:   12.9 | output: \n",
      "    {'cls_accuracy': 0.35996094,\n",
      "     'learning_rate': 2.2005088e-06,\n",
      "     'training_loss': 1.0958779}\n",
      "train | step:    400 | steps/sec:   13.0 | output: \n",
      "    {'cls_accuracy': 0.36558592,\n",
      "     'learning_rate': 2.9340117e-06,\n",
      "     'training_loss': 1.0923172}\n",
      "train | step:    500 | steps/sec:   13.2 | output: \n",
      "    {'cls_accuracy': 0.3769922,\n",
      "     'learning_rate': 3.6675146e-06,\n",
      "     'training_loss': 1.0896847}\n",
      "train | step:    600 | steps/sec:   13.1 | output: \n",
      "    {'cls_accuracy': 0.38214844,\n",
      "     'learning_rate': 4.4010176e-06,\n",
      "     'training_loss': 1.0867115}\n",
      "train | step:    700 | steps/sec:   12.9 | output: \n",
      "    {'cls_accuracy': 0.3875,\n",
      "     'learning_rate': 5.1345205e-06,\n",
      "     'training_loss': 1.0821892}\n",
      "train | step:    800 | steps/sec:   12.9 | output: \n",
      "    {'cls_accuracy': 0.39867187,\n",
      "     'learning_rate': 5.8680234e-06,\n",
      "     'training_loss': 1.0792761}\n",
      "train | step:    900 | steps/sec:   13.2 | output: \n",
      "    {'cls_accuracy': 0.4254297,\n",
      "     'learning_rate': 6.6015264e-06,\n",
      "     'training_loss': 1.0580225}\n",
      "train | step:   1000 | steps/sec:   12.8 | output: \n",
      "    {'cls_accuracy': 0.45574218,\n",
      "     'learning_rate': 7.3350293e-06,\n",
      "     'training_loss': 1.0320753}\n",
      "train | step:   1100 | steps/sec:   13.0 | output: \n",
      "    {'cls_accuracy': 0.46433595,\n",
      "     'learning_rate': 8.068533e-06,\n",
      "     'training_loss': 1.0235447}\n",
      "train | step:   1200 | steps/sec:   13.0 | output: \n",
      "    {'cls_accuracy': 0.48039064,\n",
      "     'learning_rate': 8.802035e-06,\n",
      "     'training_loss': 1.0079126}\n",
      "train | step:   1300 | steps/sec:   13.0 | output: \n",
      "    {'cls_accuracy': 0.4966797,\n",
      "     'learning_rate': 9.535539e-06,\n",
      "     'training_loss': 0.9909804}\n",
      "train | step:   1400 | steps/sec:   13.1 | output: \n",
      "    {'cls_accuracy': 0.50753903,\n",
      "     'learning_rate': 1.0269041e-05,\n",
      "     'training_loss': 0.97820604}\n",
      "train | step:   1500 | steps/sec:   13.0 | output: \n",
      "    {'cls_accuracy': 0.51496094,\n",
      "     'learning_rate': 1.1002545e-05,\n",
      "     'training_loss': 0.96822304}\n",
      "train | step:   1600 | steps/sec:   13.1 | output: \n",
      "    {'cls_accuracy': 0.52316403,\n",
      "     'learning_rate': 1.1736047e-05,\n",
      "     'training_loss': 0.95885473}\n",
      "train | step:   1700 | steps/sec:   12.8 | output: \n",
      "    {'cls_accuracy': 0.53191406,\n",
      "     'learning_rate': 1.2469551e-05,\n",
      "     'training_loss': 0.95363826}\n",
      "train | step:   1800 | steps/sec:   12.7 | output: \n",
      "    {'cls_accuracy': 0.5364063,\n",
      "     'learning_rate': 1.3203053e-05,\n",
      "     'training_loss': 0.9481234}\n",
      "train | step:   1900 | steps/sec:   12.9 | output: \n",
      "    {'cls_accuracy': 0.54132813,\n",
      "     'learning_rate': 1.3936556e-05,\n",
      "     'training_loss': 0.943616}\n",
      "train | step:   2000 | steps/sec:   13.0 | output: \n",
      "    {'cls_accuracy': 0.5420312,\n",
      "     'learning_rate': 1.4670059e-05,\n",
      "     'training_loss': 0.93882424}\n",
      "saved checkpoint to gs://jk-tpu-staging/model/ckpt-2000.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<official.nlp.modeling.models.bert_classifier.BertClassifier at 0x7f23202d3350>,\n",
       " {})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lib.run_experiment(\n",
    "        distribution_strategy=distribution_strategy,\n",
    "        task=task,\n",
    "        mode='train',\n",
    "        params=params,\n",
    "        model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tpu.ipynb",
   "toc_visible": true
  },
  "environment": {
   "name": "common-cpu.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m75"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
