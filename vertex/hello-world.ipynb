{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97be710-3917-4856-8a77-9262d877f9ad",
   "metadata": {},
   "source": [
    "# Using TPUs with Vertex AI Training - Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abf4b434-3974-4917-9902-324f661f82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import aiplatform as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c756e5c6-514a-4eef-8d94-99f32b5f5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(aip.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a18bf0-db55-4fd5-95da-d007abd33e2c",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "462bb58a-454b-4341-ab86-283e705c54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "STAGING_BUCKET = 'gs://jk-tpu-staging'\n",
    "VERTEX_SA = f'vertex-sa@{PROJECT}.iam.gserviceaccount.com'\n",
    "\n",
    "IMAGE_NAME = 'tpu-test'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT}/{IMAGE_NAME}'\n",
    "\n",
    "# Use TPU Accelerators. Temporarily using numeric codes, until types are added to the SDK\n",
    "#   6 = TPU_V2\n",
    "#   7 = TPU_V3\n",
    "TRAIN_TPU, TRAIN_NTPU = (7, 8)\n",
    "TRAIN_COMPUTE = \"cloud-tpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d5c8e-89f5-4b24-8494-5ac3a073cb92",
   "metadata": {},
   "source": [
    "## Build a custom training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "177e482e-2171-41eb-ad66-a1e700d3fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_FOLDER = 'trainer'\n",
    "\n",
    "path = Path(TRAINER_FOLDER)\n",
    "if path.exists():\n",
    "    shutil.rmtree(path)\n",
    "path.mkdir() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75bff860-9d53-4565-b166-1c76a10df8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_FOLDER}/__init__.py\n",
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e82eccd-68fa-45c3-b06d-2fa313f13fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_FOLDER}/task.py\n",
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Any, Mapping, MutableMapping, Optional, Sequence, Union\n",
    "\n",
    "from absl import logging\n",
    "from absl import flags\n",
    "from absl import app\n",
    "\n",
    "\n",
    "def train_eval():\n",
    "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "def _main(argv):\n",
    "    train_eval():\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_list('training_data_paths', None, 'Paths to training datasets')\n",
    "flags.DEFINE_list('validation_data_paths', None, 'Paths to validation datasets') \n",
    "flags.DEFINE_integer('tpu_cores', 8, 'A number of TPU cores')\n",
    "flags.DEFINE_string('tpu_type', 6, 'TPU type: 6 = TPU_V2, 7 = TPU_V3')\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #flags.mark_flags_as_required([\n",
    "    #    'fasta_path',\n",
    "    #    'database_paths',\n",
    "    #    'output_dir'\n",
    "    #])\n",
    "    app.run(_main)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57e072c0-0d0c-43a3-9f02-088cf60f4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM us-docker.pkg.dev/vertex-ai/training/tf-tpu.2-8\n",
    "\n",
    "WORKDIR /\n",
    "ADD trainer /trainer\n",
    "\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d86e01d9-caf1-47fe-8064-6846da00a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon     64kB\n",
      "Step 1/4 : FROM us-docker.pkg.dev/vertex-ai/training/tf-tpu.2-8\n",
      " ---> c182456fc8d1\n",
      "Step 2/4 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 91ce71b658fc\n",
      "Step 3/4 : ADD trainer /trainer\n",
      " ---> df344db32310\n",
      "Step 4/4 : ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
      " ---> Running in cf6650d9204a\n",
      "Removing intermediate container cf6650d9204a\n",
      " ---> 9d68a7fe721d\n",
      "Successfully built 9d68a7fe721d\n",
      "Successfully tagged gcr.io/jk-mlops-dev/tpu-test:latest\n",
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/tpu-test]\n",
      "\n",
      "\u001b[1B9da9bd55: Preparing \n",
      "\u001b[1B95c7b436: Preparing \n",
      "\u001b[1Bf663075e: Preparing \n",
      "\u001b[1B8d708c85: Preparing \n",
      "\u001b[1B2f24f403: Preparing \n",
      "\u001b[1B58b94eaf: Preparing \n",
      "\u001b[2B58b94eaf: Preparing \n",
      "\u001b[1Bed2ba73d: Preparing \n",
      "\u001b[1Ba3410843: Preparing \n",
      "\u001b[1Bb410a533: Preparing \n",
      "\u001b[1Bcd721701: Preparing \n",
      "\u001b[1B7bb57e52: Preparing \n",
      "\u001b[1B4301e47a: Preparing \n",
      "\u001b[1Bd419225a: Preparing \n",
      "\u001b[1Bfa7b148c: Preparing \n",
      "\u001b[1Bb7176e36: Preparing \n",
      "\u001b[1B867f895f: Preparing \n",
      "\u001b[1B6191ec88: Preparing \n",
      "\u001b[1B1d45eabe: Preparing \n",
      "\u001b[1B37d831ed: Preparing \n",
      "\u001b[1B676e02a3: Preparing \n",
      "\u001b[1Bb5e16f3e: Preparing \n",
      "\u001b[1B0d9979b6: Preparing \n",
      "\u001b[1B16e58f38: Preparing \n",
      "\u001b[1B3b137a55: Preparing \n",
      "\u001b[1B4f30a7dc: Preparing \n",
      "\u001b[1B7b830f1c: Preparing \n",
      "\u001b[1B63eccc3a: Preparing \n",
      "\u001b[1Bd6ebb3bb: Preparing \n",
      "\u001b[1Bb8d09b8d: Preparing \n",
      "\u001b[1Bedd6e8c1: Preparing \n",
      "\u001b[1Bcc6e5dbb: Preparing \n",
      "\u001b[1B458828ec: Preparing \n",
      "\u001b[1B05b4e4ec: Preparing \n",
      "\u001b[1B7af15d6b: Preparing \n",
      "\u001b[1B9246eef6: Preparing \n",
      "\u001b[1Bc6686132: Preparing \n",
      "\u001b[1Bcd6ba176: Preparing \n",
      "\u001b[1Bdd227beb: Preparing \n",
      "\u001b[1B0739e4a1: Preparing \n",
      "\u001b[1Bcf8b9cae: Preparing \n",
      "\u001b[1B895b8ca7: Preparing \n",
      "\u001b[43Bda9bd55: Pushed lready exists 5kB\u001b[43A\u001b[2K\u001b[38A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[29A\u001b[2K\u001b[25A\u001b[2K\u001b[22A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[43A\u001b[2Klatest: digest: sha256:066b933d96b9cb7f868946db9a23b9b4f5206c424bb16bff818e717ba8cf16d5 size: 9936\n"
     ]
    }
   ],
   "source": [
    "!docker build -t {IMAGE_URI} .\n",
    "!docker push {IMAGE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5467c41a-ce24-44eb-adfd-1b757c34846d",
   "metadata": {},
   "source": [
    "## Configure and submit a custom training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb823a4b-1c8e-44ec-82c0-5b4d8f6576de",
   "metadata": {},
   "source": [
    "### Initialize Vertex SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6a23f27-4ad6-4ee6-b039-497078bf274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd5628-e053-482f-aef3-751aa12fad62",
   "metadata": {},
   "source": [
    "### Configure worker pool specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6e852c6-ed03-4182-aa1e-de200bf02a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'container_spec': {'image_uri': 'gcr.io/jk-mlops-dev/tpu-test'}, 'replica_count': 1, 'machine_spec': {'machine_type': 'cloud-tpu', 'accelerator_type': 7, 'accelerator_count': 8}}\n"
     ]
    }
   ],
   "source": [
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"container_spec\": {\n",
    "            #\"args\": TRAINER_ARGS,\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAIN_COMPUTE,\n",
    "            \"accelerator_type\": TRAIN_TPU,\n",
    "            \"accelerator_count\": TRAIN_NTPU,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "print(worker_pool_specs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532ca68-c4ed-4675-80d5-c28d04d322cc",
   "metadata": {},
   "source": [
    "### Submit a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b7baaf5-128a-4d9a-a025-3d3a7b4b4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = f'tpu_hello_world_{time.strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "job = aip.CustomJob(display_name=display_name, worker_pool_specs=worker_pool_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a846b-4041-4d10-ba03-a0f6098d3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/5775378888695742464\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/5775378888695742464')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5775378888695742464?project=895222332033\n"
     ]
    }
   ],
   "source": [
    "job.run(sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043e096-ba32-40de-a1a3-6143ee2d4f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
