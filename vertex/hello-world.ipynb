{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97be710-3917-4856-8a77-9262d877f9ad",
   "metadata": {},
   "source": [
    "# Using TPUs with Vertex AI Training - Hello World"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abf4b434-3974-4917-9902-324f661f82a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import aiplatform as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c756e5c6-514a-4eef-8d94-99f32b5f5275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(aip.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a18bf0-db55-4fd5-95da-d007abd33e2c",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "462bb58a-454b-4341-ab86-283e705c54a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "STAGING_BUCKET = 'gs://jk-tpu-staging'\n",
    "VERTEX_SA = f'vertex-sa@{PROJECT}.iam.gserviceaccount.com'\n",
    "\n",
    "IMAGE_NAME = 'tpu-test'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT}/{IMAGE_NAME}'\n",
    "\n",
    "# Use TPU Accelerators. Temporarily using numeric codes, until types are added to the SDK\n",
    "#   6 = TPU_V2\n",
    "#   7 = TPU_V3\n",
    "TRAIN_TPU, TRAIN_NTPU = (7, 8)\n",
    "TRAIN_COMPUTE = \"cloud-tpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758d5c8e-89f5-4b24-8494-5ac3a073cb92",
   "metadata": {},
   "source": [
    "## Build a custom training container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "177e482e-2171-41eb-ad66-a1e700d3fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_FOLDER = 'trainer'\n",
    "\n",
    "path = Path(TRAINER_FOLDER)\n",
    "if path.exists():\n",
    "    shutil.rmtree(path)\n",
    "path.mkdir() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75bff860-9d53-4565-b166-1c76a10df8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_FOLDER}/__init__.py\n",
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e82eccd-68fa-45c3-b06d-2fa313f13fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_FOLDER}/task.py\n",
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from typing import Any, Mapping, MutableMapping, Optional, Sequence, Union\n",
    "\n",
    "from absl import logging\n",
    "from absl import flags\n",
    "from absl import app\n",
    "\n",
    "\n",
    "def train_eval():\n",
    "    cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=\"local\")\n",
    "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
    "    print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "def _main(argv):\n",
    "    train_eval()\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_list('training_data_paths', None, 'Paths to training datasets')\n",
    "flags.DEFINE_list('validation_data_paths', None, 'Paths to validation datasets') \n",
    "flags.DEFINE_integer('tpu_cores', 8, 'A number of TPU cores')\n",
    "flags.DEFINE_string('tpu_type', 6, 'TPU type: 6 = TPU_V2, 7 = TPU_V3')\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #flags.mark_flags_as_required([\n",
    "    #    'fasta_path',\n",
    "    #    'database_paths',\n",
    "    #    'output_dir'\n",
    "    #])\n",
    "    app.run(_main)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57e072c0-0d0c-43a3-9f02-088cf60f4d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "\n",
    "FROM us-docker.pkg.dev/vertex-ai/training/tf-tpu.2-8\n",
    "\n",
    "WORKDIR /\n",
    "ADD trainer /trainer\n",
    "\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d86e01d9-caf1-47fe-8064-6846da00a5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon     64kB\n",
      "Step 1/4 : FROM us-docker.pkg.dev/vertex-ai/training/tf-tpu.2-8\n",
      " ---> c182456fc8d1\n",
      "Step 2/4 : WORKDIR /\n",
      " ---> Using cache\n",
      " ---> 91ce71b658fc\n",
      "Step 3/4 : ADD trainer /trainer\n",
      " ---> df344db32310\n",
      "Step 4/4 : ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
      " ---> Running in cf6650d9204a\n",
      "Removing intermediate container cf6650d9204a\n",
      " ---> 9d68a7fe721d\n",
      "Successfully built 9d68a7fe721d\n",
      "Successfully tagged gcr.io/jk-mlops-dev/tpu-test:latest\n",
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/tpu-test]\n",
      "\n",
      "\u001b[1B9da9bd55: Preparing \n",
      "\u001b[1B95c7b436: Preparing \n",
      "\u001b[1Bf663075e: Preparing \n",
      "\u001b[1B8d708c85: Preparing \n",
      "\u001b[1B2f24f403: Preparing \n",
      "\u001b[1B58b94eaf: Preparing \n",
      "\u001b[2B58b94eaf: Preparing \n",
      "\u001b[1Bed2ba73d: Preparing \n",
      "\u001b[1Ba3410843: Preparing \n",
      "\u001b[1Bb410a533: Preparing \n",
      "\u001b[1Bcd721701: Preparing \n",
      "\u001b[1B7bb57e52: Preparing \n",
      "\u001b[1B4301e47a: Preparing \n",
      "\u001b[1Bd419225a: Preparing \n",
      "\u001b[1Bfa7b148c: Preparing \n",
      "\u001b[1Bb7176e36: Preparing \n",
      "\u001b[1B867f895f: Preparing \n",
      "\u001b[1B6191ec88: Preparing \n",
      "\u001b[1B1d45eabe: Preparing \n",
      "\u001b[1B37d831ed: Preparing \n",
      "\u001b[1B676e02a3: Preparing \n",
      "\u001b[1Bb5e16f3e: Preparing \n",
      "\u001b[1B0d9979b6: Preparing \n",
      "\u001b[1B16e58f38: Preparing \n",
      "\u001b[1B3b137a55: Preparing \n",
      "\u001b[1B4f30a7dc: Preparing \n",
      "\u001b[1B7b830f1c: Preparing \n",
      "\u001b[1B63eccc3a: Preparing \n",
      "\u001b[1Bd6ebb3bb: Preparing \n",
      "\u001b[1Bb8d09b8d: Preparing \n",
      "\u001b[1Bedd6e8c1: Preparing \n",
      "\u001b[1Bcc6e5dbb: Preparing \n",
      "\u001b[1B458828ec: Preparing \n",
      "\u001b[1B05b4e4ec: Preparing \n",
      "\u001b[1B7af15d6b: Preparing \n",
      "\u001b[1B9246eef6: Preparing \n",
      "\u001b[1Bc6686132: Preparing \n",
      "\u001b[1Bcd6ba176: Preparing \n",
      "\u001b[1Bdd227beb: Preparing \n",
      "\u001b[1B0739e4a1: Preparing \n",
      "\u001b[1Bcf8b9cae: Preparing \n",
      "\u001b[1B895b8ca7: Preparing \n",
      "\u001b[43Bda9bd55: Pushed lready exists 5kB\u001b[43A\u001b[2K\u001b[38A\u001b[2K\u001b[36A\u001b[2K\u001b[32A\u001b[2K\u001b[29A\u001b[2K\u001b[25A\u001b[2K\u001b[22A\u001b[2K\u001b[19A\u001b[2K\u001b[15A\u001b[2K\u001b[12A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[43A\u001b[2Klatest: digest: sha256:066b933d96b9cb7f868946db9a23b9b4f5206c424bb16bff818e717ba8cf16d5 size: 9936\n"
     ]
    }
   ],
   "source": [
    "!docker build -t {IMAGE_URI} .\n",
    "!docker push {IMAGE_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5467c41a-ce24-44eb-adfd-1b757c34846d",
   "metadata": {},
   "source": [
    "## Configure and submit a custom training job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb823a4b-1c8e-44ec-82c0-5b4d8f6576de",
   "metadata": {},
   "source": [
    "### Initialize Vertex SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6a23f27-4ad6-4ee6-b039-497078bf274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aip.init(project=PROJECT_ID, staging_bucket=STAGING_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dd5628-e053-482f-aef3-751aa12fad62",
   "metadata": {},
   "source": [
    "### Configure worker pool specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6e852c6-ed03-4182-aa1e-de200bf02a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'container_spec': {'image_uri': 'gcr.io/jk-mlops-dev/tpu-test'}, 'replica_count': 1, 'machine_spec': {'machine_type': 'cloud-tpu', 'accelerator_type': 7, 'accelerator_count': 8}}\n"
     ]
    }
   ],
   "source": [
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"container_spec\": {\n",
    "            #\"args\": TRAINER_ARGS,\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": TRAIN_COMPUTE,\n",
    "            \"accelerator_type\": TRAIN_TPU,\n",
    "            \"accelerator_count\": TRAIN_NTPU,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "print(worker_pool_specs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4532ca68-c4ed-4675-80d5-c28d04d322cc",
   "metadata": {},
   "source": [
    "### Submit a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8b7baaf5-128a-4d9a-a025-3d3a7b4b4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = f'tpu_hello_world_{time.strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "job = aip.CustomJob(display_name=display_name, worker_pool_specs=worker_pool_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d5a846b-4041-4d10-ba03-a0f6098d3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/5775378888695742464\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/5775378888695742464')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5775378888695742464?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5775378888695742464 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5775378888695742464 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5775378888695742464 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5775378888695742464 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5775378888695742464 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5775378888695742464 current state:\n",
      "JobState.JOB_STATE_FAILED\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 3\nmessage: \"The replica workerpool0-0 exited with a non-zero status of 1. To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=895222332033&resource=ml_job%2Fjob_id%2F5775378888695742464&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%225775378888695742464%22\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8146/2466108514.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, timeout, restart_job_on_worker_restart, enable_web_access, tensorboard, sync)\u001b[0m\n\u001b[1;32m   1420\u001b[0m             )\n\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_JOB_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 904\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    905\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 3\nmessage: \"The replica workerpool0-0 exited with a non-zero status of 1. To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=895222332033&resource=ml_job%2Fjob_id%2F5775378888695742464&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%225775378888695742464%22\"\n"
     ]
    }
   ],
   "source": [
    "job.run(sync=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5043e096-ba32-40de-a1a3-6143ee2d4f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-7.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-7:m87"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
